{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import train_crm\n",
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "from util.utils import get_tri\n",
    "from PIL import Image\n",
    "import nvdiffrast.torch as dr\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import kaolin as kal\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import render\n",
    "# import loss\n",
    "from util_flexi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 1000\n",
    "batch = 8\n",
    "train_res = [1024, 1024]\n",
    "voxel_grid_res = 64\n",
    "device = 'cuda'\n",
    "sdf_regularizer = 0.2\n",
    "path_to_images = \"Data/shoe0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crm_path = hf_hub_download(repo_id=\"Zhengyi/CRM\", filename=\"CRM.pth\")\n",
    "specs = json.load(open(\"configs/specs_objaverse_total.json\"))\n",
    "\n",
    "model_crm = train_crm(specs).to('cuda:0')\n",
    "model_crm.load_state_dict(torch.load(crm_path, map_location = device), strict=False)\n",
    "\n",
    "fc = model_crm.renderer.flexicubes\n",
    "grid_edges = fc.all_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add gt mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mesh = kal.io.obj.import_mesh(f'Data/gtShoe/shoe_0.obj').cuda()\n",
    "vertices = gt_mesh.vertices\n",
    "vmin, vmax = vertices.min(dim=0)[0], vertices.max(dim=0)[0]\n",
    "scale = 1.8 / torch.max(vmax - vmin).item()\n",
    "vertices = vertices - (vmax + vmin) / 2 # Center mesh on origin\n",
    "# gt_mesh.vertices = vertices * scale # Rescale to [-0.9, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path):\n",
    "    rgb=[]\n",
    "    ccm=[]\n",
    "    for i in range(6):\n",
    "            rgb_img = Image.open(f'{path}/rgb/{i}.png') #rgb image path\n",
    "            ccm_img = Image.open(f'{path}/ccm/{i}.png') #ccm image path\n",
    "            new_width  = 256\n",
    "            new_height = new_width \n",
    "            new_height = 256\n",
    "            new_width  = new_height \n",
    "            pixel_rgb_img = rgb_img.resize((new_width, new_height), Image.LANCZOS)\n",
    "            pixel_ccm_img = ccm_img.resize((new_width, new_height), Image.LANCZOS)\n",
    "            rgb_img_arr = np.asarray(pixel_rgb_img)\n",
    "            rgb_ccm_arr = np.asarray(pixel_ccm_img)\n",
    "            rgb.append(rgb_img_arr)\n",
    "            ccm.append(rgb_ccm_arr)\n",
    "\n",
    "    rgb = [Image.fromarray(img) for img in rgb]\n",
    "    ccm = [Image.fromarray(img) for img in ccm]\n",
    "    np_imgs = np.concatenate(rgb, 1)\n",
    "    np_xyzs = np.concatenate(ccm, 1)\n",
    "\n",
    "    return(np_imgs,np_xyzs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option lr schedular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(iter):\n",
    "    return max(0.0, 10 ** (-(iter) * 0.0002)) # Exponential falloff from [1.0, 0.1] over 5k epochs.\n",
    "\n",
    "optimizer = optim.Adam(model_crm.parameters(), lr=1e-4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdf_reg_loss(sdf, all_edges):\n",
    "    sdf_f1x6x2 = sdf[all_edges.reshape(-1)].reshape(-1,2)\n",
    "    mask = torch.sign(sdf_f1x6x2[...,0]) != torch.sign(sdf_f1x6x2[...,1])\n",
    "    sdf_f1x6x2 = sdf_f1x6x2[mask]\n",
    "    sdf_diff = torch.nn.functional.binary_cross_entropy_with_logits(sdf_f1x6x2[...,0], (sdf_f1x6x2[...,1] > 0).float()) + \\\n",
    "            torch.nn.functional.binary_cross_entropy_with_logits(sdf_f1x6x2[...,1], (sdf_f1x6x2[...,0] > 0).float())\n",
    "    return sdf_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3d(rgb, ccm,model):\n",
    "    color_tri = torch.from_numpy(rgb)/255\n",
    "    xyz_tri = torch.from_numpy(ccm[:,:,(2,1,0)])/255\n",
    "    color = color_tri.permute(2,0,1)\n",
    "    xyz = xyz_tri.permute(2,0,1)\n",
    "\n",
    "\n",
    "    def get_imgs(color):\n",
    "        # color : [C, H, W*6]\n",
    "        color_list = []\n",
    "        color_list.append(color[:,:,256*5:256*(1+5)])\n",
    "        for i in range(0,5):\n",
    "            color_list.append(color[:,:,256*i:256*(1+i)])\n",
    "        return torch.stack(color_list, dim=0)# [6, C, H, W]\n",
    "\n",
    "    triplane_color = get_imgs(color).permute(0,2,3,1).unsqueeze(0).to(device)# [1, 6, H, W, C]\n",
    "\n",
    "    color = get_imgs(color)\n",
    "    xyz = get_imgs(xyz)\n",
    "\n",
    "    color = get_tri(color, dim=0, blender= True, scale = 1).unsqueeze(0)\n",
    "    xyz = get_tri(xyz, dim=0, blender= True, scale = 1, fix= True).unsqueeze(0)\n",
    "\n",
    "    triplane = torch.cat([color,xyz],dim=1).to(device)\n",
    "    # 3D visualize\n",
    "    model.eval()\n",
    "    glctx = dr.RasterizeCudaContext()\n",
    "\n",
    "    if model.denoising == True:\n",
    "        tnew = 20\n",
    "        tnew = torch.randint(tnew, tnew+1, [triplane.shape[0]], dtype=torch.long, device=triplane.device)\n",
    "        noise_new = torch.randn_like(triplane) *0.5+0.5\n",
    "        triplane = model.scheduler.add_noise(triplane, noise_new, tnew)    \n",
    "        # start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            triplane_feature2 = model.unet2(triplane,tnew)\n",
    "        # end_time = time.time()\n",
    "        # elapsed_time = end_time - start_time\n",
    "        # print(f\"unet takes {elapsed_time}s\")\n",
    "    else:\n",
    "        triplane_feature2 = model.unet2(triplane)\n",
    "        \n",
    "\n",
    "    with torch.no_grad():\n",
    "        data_config = {\n",
    "            'resolution': [1024, 1024],\n",
    "            \"triview_color\": triplane_color.to(device),\n",
    "        }\n",
    "\n",
    "        result,vert,faces,weight,sdf = model.decode(data_config, triplane_feature2)\n",
    "        # print(data[1][0])\n",
    "        data_config['verts'] = vert[0]\n",
    "        data_config['faces'] = faces\n",
    "        data_config =  data_config | result\n",
    "        data_config['weight'] = weight\n",
    "        data_config['sdf'] = sdf\n",
    "    return data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb,ccm = data_loader(path_to_images)\n",
    "data_config = generate_3d(rgb,ccm,model_crm)\n",
    "flexicubes_mesh = kal.rep.SurfaceMesh(vertices=data_config['verts'], faces=data_config['faces'].to(torch.int64))\n",
    "intermediate_results = [flexicubes_mesh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = render.get_rotate_camera(0)\n",
    "f, ax = plt.subplots(1, 2)\n",
    "output = render.render_mesh(gt_mesh, camera, [512, 512], return_types=['normals'])\n",
    "ax[0].imshow(((output['normals'][0] + 1) / 2.).cpu().detach())\n",
    "output = render.render_mesh(flexicubes_mesh, camera, [512, 512], return_types=['normals'])\n",
    "ax[1].imshow(((output['normals'][0] + 1) / 2.).cpu().detach())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = tqdm.tqdm(range(iter),leave=True)\n",
    "for it in loop: \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # sample random camera poses\n",
    "    cameras = render.get_random_camera_batch(batch, iter_res=train_res, device=device)\n",
    "    \n",
    "    # render gt mesh at sampled views\n",
    "    target = render.render_mesh(gt_mesh, cameras, train_res)\n",
    "\n",
    "    data_config = generate_3d(rgb,ccm,model_crm)\n",
    "    \n",
    "    flexicubes_mesh = kal.rep.SurfaceMesh(vertices=data_config['verts'], faces=data_config['faces'].to(torch.int64))\n",
    "\n",
    "    buffers = render.render_mesh(flexicubes_mesh, cameras, train_res)\n",
    "\n",
    "    # evaluate reconstruction loss\n",
    "    mask_loss = (buffers['mask'] - target['mask']).abs().mean() # mask loss\n",
    "    depth_loss = (((((buffers['depth'] - (target['depth']))* target['mask'])**2).sum(-1)+1e-8)).sqrt().mean() * 10 # depth loss\n",
    "\n",
    "\n",
    "    # evaluate regularization losses\n",
    "    t_iter = it / iter\n",
    "    # this is the regularization loss described in Equation 2 of the nvdiffrec paper by Munkberg et al., which serves to remove internal floating elements that are not visible to the user.\n",
    "    sdf_weight = sdf_regularizer - (sdf_regularizer - sdf_regularizer/20)*min(1.0, 4.0 * t_iter)\n",
    "    sdf = torch.nn.Parameter(data_config['sdf'][0].clone().detach(), requires_grad=True)\n",
    "    reg_loss = sdf_reg_loss(sdf, grid_edges).mean() * sdf_weight\n",
    "\n",
    "    reg_loss += data_config[\"flex_surf_loss\"]*0.5 # L_dev as in Equation 8 of our paper\n",
    "    reg_loss += (data_config[\"weight\"][:,:20]).abs().mean() * 0.1  # regularize weights to be zeros to improve the stability of the optimization process\n",
    "    total_loss = 0.5*(mask_loss + depth_loss) + 0.005*reg_loss\n",
    "    \n",
    "\n",
    "    if True: # optionally add SDF loss to eliminate internal structures\n",
    "            with torch.no_grad():\n",
    "                pts = sample_random_points(1000, gt_mesh)\n",
    "                gt_sdf = compute_sdf(pts, gt_mesh.vertices, gt_mesh.faces)\n",
    "            pred_sdf = compute_sdf(pts, flexicubes_mesh.vertices, flexicubes_mesh.faces)\n",
    "            total_loss += torch.nn.functional.mse_loss(pred_sdf, gt_sdf) * 2e3\n",
    "        \n",
    "    # optionally add developability regularizer, as described in paper section 5.2\n",
    "    # if True:\n",
    "    #     reg_weight = max(0, t_iter - 0.8) * 5\n",
    "    #     if reg_weight > 0: # only applied after shape converges\n",
    "    #         reg_loss = loss.mesh_developable_reg(flexicubes_mesh).mean() * 10\n",
    "    #         reg_loss += (deform).abs().mean()\n",
    "    #         reg_loss += (weight[:,:20]).abs().mean()\n",
    "    #         total_loss = mask_loss + depth_loss + reg_loss \n",
    "            \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "    if it % 100 == 0:\n",
    "            log=open('log.txt','a')\n",
    "            log.write(f'epoch = {it} : loss = {total_loss.item()}\\n')\n",
    "            log.close()\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        log=open('log.txt','a')\n",
    "        torch.save(model_crm.state_dict(), f'checkpoints/model_weights_1_2_{it}.pth')\n",
    "        log.write(f'[Saved checkpoint] epoch = {it} : loss = {total_loss.item()}\\n')\n",
    "        log.close()\n",
    "\n",
    "    if (it + 1) % 20 == 0: # save intermediate results every 100 iters\n",
    "        with torch.no_grad():\n",
    "            # run the mesh extraction again with the parameter 'training=False' so that each quadrilateral face is divided into two triangles, as opposed to the four triangles during the training phase.\n",
    "            data_config = generate_3d(rgb,ccm,model_crm)\n",
    "            intermediate_results.append(kal.rep.SurfaceMesh(vertices=data_config['verts'], faces=data_config['faces'].to(torch.int64)))\n",
    "\n",
    "    # update tqdm loop\n",
    "    loop.set_postfix(loss = total_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_crm.state_dict(), 'model_weights_final2_lrSH.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = render.get_rotate_camera(0)\n",
    "render.TimelineVisualizer(intermediate_results, 512, 512).show(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
