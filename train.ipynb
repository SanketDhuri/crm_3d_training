{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import train_crm\n",
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "from util.utils import get_tri\n",
    "from PIL import Image\n",
    "import nvdiffrast.torch as dr\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import kaolin as kal\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import render\n",
    "import loss\n",
    "from util_flexi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 1000\n",
    "batch = 8\n",
    "train_res = [1024, 1024]\n",
    "learning_rate = 0.01\n",
    "voxel_grid_res = 64\n",
    "device = 'cuda'\n",
    "sdf_regularizer = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crm_path = hf_hub_download(repo_id=\"Zhengyi/CRM\", filename=\"CRM.pth\")\n",
    "specs = json.load(open(\"configs/specs_objaverse_total.json\"))\n",
    "\n",
    "model_crm = train_crm(specs).to('cuda:0')\n",
    "model_crm.load_state_dict(torch.load(crm_path, map_location = device), strict=False)\n",
    "# model_crm.load_state_dict(torch.load('model_weights_final2.pth', map_location = device), strict=False)\n",
    "\n",
    "fc = model_crm.renderer.flexicubes\n",
    "x_nx3 = fc.verts\n",
    "sdf = torch.rand_like(x_nx3[:,0]) - 0.1\n",
    "sdf = torch.nn.Parameter(sdf.clone().detach(), requires_grad=True)\n",
    "\n",
    "grid_edges = fc.all_edges\n",
    "\n",
    "\n",
    "gt_mesh = kal.io.obj.import_mesh('GT_shoe/gtShoe_1.obj').cuda()\n",
    "vertices = gt_mesh.vertices\n",
    "vmin, vmax = vertices.min(dim=0)[0], vertices.max(dim=0)[0]\n",
    "scale = 1.8 / torch.max(vmax - vmin).item()\n",
    "vertices = vertices - (vmax + vmin) / 2 # Center mesh on origin\n",
    "gt_mesh.vertices = vertices * scale # Rescale to [-0.9, 0.9]\n",
    "\n",
    "\n",
    "# fc = kal.non_commercial.FlexiCubes(device)\n",
    "# x_nx3, cube_fx8 = fc.construct_voxel_grid(voxel_grid_res)\n",
    "# x_nx3 *= 2 # scale up the grid so that it's larger than the target object\n",
    "# sdf = torch.rand_like(x_nx3[:,0]) - 0.1 # randomly initialize SDF\n",
    "# sdf = torch.nn.Parameter(sdf.clone().detach(), requires_grad=True)\n",
    "# # set per-cube learnable weights to zeros\n",
    "# weight = torch.zeros((cube_fx8.shape[0], 21), dtype=torch.float, device='cuda') \n",
    "# weight = torch.nn.Parameter(weight.clone().detach(), requires_grad=True)\n",
    "\n",
    "# #  Retrieve all the edges of the voxel grid; these edges will be utilized to \n",
    "# #  compute the regularization loss in subsequent steps of the process.\n",
    "# all_edges = cube_fx8[:, fc.cube_edges].reshape(-1, 2) \n",
    "# grid_edges = torch.unique(all_edges, dim=0)\n",
    "# print(model_crm.parameters())\n",
    "# Define optimizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(data_num:int):\n",
    "    rgb=[]\n",
    "    for i in range(6):\n",
    "            img = Image.open(f'shoe{data_num}_processed/1{i}.png')\n",
    "\n",
    "            new_width  = 256\n",
    "            new_height = new_width \n",
    "            new_height = 256\n",
    "            new_width  = new_height \n",
    "            pixel_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "            # print(pixel_img.size)\n",
    "            arr = np.asarray(pixel_img)\n",
    "            rgb.append(arr)\n",
    "\n",
    "    rgb = [Image.fromarray(img) for img in rgb]\n",
    "    ccm = [Image.open(f'shoe{data_num}_normals/{i}.png') for i in range(6)]\n",
    "    np_imgs = np.concatenate(rgb, 1)\n",
    "    np_xyzs = np.concatenate(ccm, 1)\n",
    "    # gt_sdf = get_gt_sdf(mesh1_sdf)\n",
    "\n",
    "    return(np_imgs,np_xyzs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(iter):\n",
    "    return max(0.0, 10 ** (-(iter) * 0.0002)) # Exponential falloff from [1.0, 0.1] over 5k epochs.   \n",
    "# Define optimizer \n",
    "optimizer = optim.Adam(model_crm.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: lr_schedule(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3d(rgb, ccm,model):\n",
    "    color_tri = torch.from_numpy(rgb)/255\n",
    "    xyz_tri = torch.from_numpy(ccm[:,:,(2,1,0)])/255\n",
    "    color = color_tri.permute(2,0,1)\n",
    "    xyz = xyz_tri.permute(2,0,1)\n",
    "\n",
    "\n",
    "    def get_imgs(color):\n",
    "        # color : [C, H, W*6]\n",
    "        color_list = []\n",
    "        color_list.append(color[:,:,256*5:256*(1+5)])\n",
    "        for i in range(0,5):\n",
    "            color_list.append(color[:,:,256*i:256*(1+i)])\n",
    "        return torch.stack(color_list, dim=0)# [6, C, H, W]\n",
    "\n",
    "    triplane_color = get_imgs(color).permute(0,2,3,1).unsqueeze(0).to(device)# [1, 6, H, W, C]\n",
    "\n",
    "    color = get_imgs(color)\n",
    "    xyz = get_imgs(xyz)\n",
    "\n",
    "    color = get_tri(color, dim=0, blender= True, scale = 1).unsqueeze(0)\n",
    "    xyz = get_tri(xyz, dim=0, blender= True, scale = 1, fix= True).unsqueeze(0)\n",
    "\n",
    "    triplane = torch.cat([color,xyz],dim=1).to(device)\n",
    "    # 3D visualize\n",
    "    model.eval()\n",
    "    glctx = dr.RasterizeCudaContext()\n",
    "\n",
    "    if model.denoising == True:\n",
    "        tnew = 20\n",
    "        tnew = torch.randint(tnew, tnew+1, [triplane.shape[0]], dtype=torch.long, device=triplane.device)\n",
    "        noise_new = torch.randn_like(triplane) *0.5+0.5\n",
    "        triplane = model.scheduler.add_noise(triplane, noise_new, tnew)    \n",
    "        # start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            triplane_feature2 = model.unet2(triplane,tnew)\n",
    "        # end_time = time.time()\n",
    "        # elapsed_time = end_time - start_time\n",
    "        # print(f\"unet takes {elapsed_time}s\")\n",
    "    else:\n",
    "        triplane_feature2 = model.unet2(triplane)\n",
    "        \n",
    "\n",
    "    with torch.no_grad():\n",
    "        data_config = {\n",
    "            'resolution': [1024, 1024],\n",
    "            \"triview_color\": triplane_color.to(device),\n",
    "        }\n",
    "\n",
    "        result,vert,faces,weight = model.decode(data_config, triplane_feature2)\n",
    "        # print(data[1][0])\n",
    "        data_config['verts'] = vert[0]\n",
    "        data_config['faces'] = faces\n",
    "        data_config =  data_config | result\n",
    "        data_config['weight'] = weight\n",
    "    return data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb,ccm = data_loader(1)\n",
    "data_config = generate_3d(rgb,ccm,model_crm)\n",
    "flexicubes_mesh = kal.rep.SurfaceMesh(vertices=data_config['verts'], faces=data_config['faces'].to(torch.int64))\n",
    "intermediate_results = [flexicubes_mesh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:12:03<00:00,  4.32s/it, loss=0.522]\n"
     ]
    }
   ],
   "source": [
    "loop = tqdm.tqdm(range(iter),leave=True)\n",
    "for it in loop: \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # sample random camera poses\n",
    "    cameras = render.get_random_camera_batch(batch, iter_res=train_res, device=device)\n",
    "    \n",
    "    # render gt mesh at sampled views\n",
    "    target = render.render_mesh(gt_mesh, cameras, train_res)\n",
    "\n",
    "    data_config = generate_3d(rgb,ccm,model_crm)\n",
    "    \n",
    "    flexicubes_mesh = kal.rep.SurfaceMesh(vertices=data_config['verts'], faces=data_config['faces'].to(torch.int64))\n",
    "\n",
    "    buffers = render.render_mesh(flexicubes_mesh, cameras, train_res)\n",
    "\n",
    "    # evaluate reconstruction loss\n",
    "    mask_loss = (buffers['mask'] - target['mask']).abs().mean() # mask loss\n",
    "    depth_loss = (((((buffers['depth'] - (target['depth']))* target['mask'])**2).sum(-1)+1e-8)).sqrt().mean() * 10 # depth loss\n",
    "\n",
    "\n",
    "    # evaluate regularization losses\n",
    "    t_iter = it / iter\n",
    "    # this is the regularization loss described in Equation 2 of the nvdiffrec paper by Munkberg et al., which serves to remove internal floating elements that are not visible to the user.\n",
    "    sdf_weight = sdf_regularizer - (sdf_regularizer - sdf_regularizer/20)*min(1.0, 4.0 * t_iter)\n",
    "    reg_loss = loss.sdf_reg_loss(sdf, grid_edges).mean() * sdf_weight\n",
    "\n",
    "    reg_loss += data_config[\"flex_surf_loss\"]*0.5 # L_dev as in Equation 8 of our paper\n",
    "    reg_loss += (data_config[\"weight\"][:,:20]).abs().mean() * 0.1  # regularize weights to be zeros to improve the stability of the optimization process\n",
    "    total_loss = mask_loss + depth_loss + reg_loss\n",
    "    \n",
    "\n",
    "    if True: # optionally add SDF loss to eliminate internal structures\n",
    "            with torch.no_grad():\n",
    "                pts = sample_random_points(1000, gt_mesh)\n",
    "                gt_sdf = compute_sdf(pts, gt_mesh.vertices, gt_mesh.faces)\n",
    "            pred_sdf = compute_sdf(pts, flexicubes_mesh.vertices, flexicubes_mesh.faces)\n",
    "            total_loss += torch.nn.functional.mse_loss(pred_sdf, gt_sdf) * 2e3\n",
    "        \n",
    "    # optionally add developability regularizer, as described in paper section 5.2\n",
    "    # if True:\n",
    "    #     reg_weight = max(0, t_iter - 0.8) * 5\n",
    "    #     if reg_weight > 0: # only applied after shape converges\n",
    "    #         reg_loss = loss.mesh_developable_reg(flexicubes_mesh).mean() * 10\n",
    "    #         reg_loss += (deform).abs().mean()\n",
    "    #         reg_loss += (weight[:,:20]).abs().mean()\n",
    "    #         total_loss = mask_loss + depth_loss + reg_loss \n",
    "            \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    if it % 100 == 0:\n",
    "            log=open('log.txt','a')\n",
    "            log.write(f'epoch = {it} : loss = {total_loss.item()}\\n')\n",
    "            log.close()\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        log=open('log.txt','a')\n",
    "        torch.save(model_crm.state_dict(), f'checkpoints/model_weights_1_2_{it}.pth')\n",
    "        log.write(f'[Saved checkpoint] epoch = {it} : loss = {total_loss.item()}\\n')\n",
    "        log.close()\n",
    "\n",
    "    if (it + 1) % 20 == 0: # save intermediate results every 100 iters\n",
    "        with torch.no_grad():\n",
    "            # run the mesh extraction again with the parameter 'training=False' so that each quadrilateral face is divided into two triangles, as opposed to the four triangles during the training phase.\n",
    "            data_config = generate_3d(rgb,ccm,model_crm)\n",
    "            intermediate_results.append(kal.rep.SurfaceMesh(vertices=data_config['verts'], faces=data_config['faces'].to(torch.int64)))\n",
    "\n",
    "    # update tqdm loop\n",
    "    loop.set_postfix(loss = total_loss.item())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_crm.state_dict(), 'model_weights_final2_lrSH.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e66f9b81ba4bd99ecbf4d167686444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=512, width=512), interactive(children=(FloatLogSlider(value=0.3981071705534972, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68f0f5e7d3c4b7cbe36fd694009306b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera = render.get_rotate_camera(0)\n",
    "render.TimelineVisualizer(intermediate_results, 512, 512).show(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
